{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb26f11",
   "metadata": {},
   "source": [
    "# Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204110f6",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a066bf5",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd20fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from chapter4 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,    #1\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,       #2\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897f0985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from chapter4 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)    #1\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)                #2\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41db956",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbcbb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2385e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfcc899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():     #1\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)     #2\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d211bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82ee36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892a6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6dd99f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76cb29e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58199c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8c066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e964efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a30c4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f12527",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd8fcf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f982aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6da9268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f9c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter2 import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb2f4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "173262d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)         #1\n",
    "    target_batch = target_batch.to(device)      \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d077742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)     #1\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))   #2\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()    #3\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches    #4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdd23810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)   #1\n",
    "with torch.no_grad():                                        #2\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)    #3\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ceef6",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "926fdbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []    #1\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):    #2\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()   #3\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()                     #4\n",
    "            optimizer.step()                    #5\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:    #6\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(                      #7\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a7d51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  #1\n",
    "    with torch.no_grad():                              #2\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5a21324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))      #1\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2df28251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.928\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.600\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.586, Val loss 6.477\n",
      "Ep 3 (Step 000025): Train loss 5.528, Val loss 6.400\n",
      "Every effort moves you, and, and, and, and, and, and, and of the of the of the of the to the St, and, and the of the of the to the, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.142, Val loss 6.377\n",
      "Ep 4 (Step 000035): Train loss 4.973, Val loss 6.375\n",
      "Every effort moves you a a to the a. Gisburn, and a. Gisburn. I had been. I had been. Gisburn. I had a of the a, and a. I had the of the of the of the of the\n",
      "Ep 5 (Step 000040): Train loss 4.365, Val loss 6.261\n",
      "Every effort moves you, I had been a--as of the picture, I had been. \"Oh, I had been the fact of the picture to me--and it was a little--and it--and it was a little the of the picture of the\n",
      "Ep 6 (Step 000045): Train loss 3.995, Val loss 6.193\n",
      "Ep 6 (Step 000050): Train loss 3.486, Val loss 6.156\n",
      "Every effort moves you know the        \"I had the last word.                   \"Oh, and he was, and down the room, and I\n",
      "Ep 7 (Step 000055): Train loss 3.504, Val loss 6.190\n",
      "Ep 7 (Step 000060): Train loss 2.699, Val loss 6.132\n",
      "Every effort moves you know the picture to see the picture.                    \"I he was his pictures-c.             \n",
      "Ep 8 (Step 000065): Train loss 2.250, Val loss 6.141\n",
      "Ep 8 (Step 000070): Train loss 1.917, Val loss 6.225\n",
      "Every effort moves you know,\" was one of the picture.  \"I had the last word. Gisburn's an!  \"Oh, in the moment--as Jack himself, as he was his own the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.535, Val loss 6.227\n",
      "Ep 9 (Step 000080): Train loss 1.209, Val loss 6.248\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that Mrs. \"Yes--and by me to me to have to see a smile behind his close grayish beard--as, I had the donkey. \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss 0.927, Val loss 6.322\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"         He placed them at my elbow and as I turned, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),           #1\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43f40027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                   #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)     #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e3947",
   "metadata": {},
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dd4ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc3b3af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943fcf8",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd1e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8515243",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "218ba0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0da624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f810763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "             for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9effb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a89430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]                                     #1\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], \n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8972c",
   "metadata": {},
   "source": [
    "### EXERCISE 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "608ac91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d008db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5b79705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccdf21",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd1af548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0bbecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],    #1\n",
    "    input=torch.tensor(float('-inf')),     #2\n",
    "    other=next_token_logits     #3\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e100a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd8398",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59c47c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):            #1\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:                #2\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:                  #3\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:    #4\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:              #5\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fce4bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youlit did an down surprise, one of his! that lifted the spacious\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7e215",
   "metadata": {},
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5abb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34256d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc4ab291",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "881ac164",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a5ae6",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bd678a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7ff148ee6fb0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ab6d519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 03:30:55.738332: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-26 03:30:55.802677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-26 03:30:56.949371: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "checkpoint: 100%|████████████████████████████████████████████████████████████████████████| 77.0/77.0 [00:00<00:00, 120kiB/s]\n",
      "encoder.json: 100%|███████████████████████████████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 1.09MiB/s]\n",
      "hparams.json: 100%|██████████████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 163kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|███████████████████████████████████████████████████| 498M/498M [05:47<00:00, 1.43MiB/s]\n",
      "model.ckpt.index: 100%|███████████████████████████████████████████████████████████████| 5.21k/5.21k [00:00<00:00, 7.71MiB/s]\n",
      "model.ckpt.meta: 100%|███████████████████████████████████████████████████████████████████| 471k/471k [00:00<00:00, 730kiB/s]\n",
      "vocab.bpe: 100%|█████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 707kiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dc9da53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b6e46fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2867bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "942c7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9af3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbdc8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb3e70f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e58de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ee14417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):           #1\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):     #2\n",
    "        q_w, k_w, v_w = np.split(                            #3\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])    #4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9054524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0f0778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8abefc",
   "metadata": {},
   "source": [
    "### EXERCISE 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5619926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.754763205846151\n",
      "Validation loss: 3.559634208679199\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device)   #1\n",
    "with torch.no_grad():                                        #2\n",
    "    train_loss = calc_loss_loader(train_loader, gpt, device)    #3\n",
    "    val_loss = calc_loss_loader(val_loader, gpt, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d70f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
